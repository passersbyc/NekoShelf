import os
import re
import difflib
import shlex
import shutil
import datetime

from ..import_engine import ImportEngine
from ..config import VERSION
from ..utils import Colors, simple_complete, path_complete, get_logger


class SystemCommandsMixin:
    def do_version(self, arg):
        """æ˜¾ç¤ºå½“å‰ç‰ˆæœ¬ä¿¡æ¯"""
        print(f"{Colors.GREEN}NekoShelf v{VERSION}{Colors.RESET}")
        print(f"{Colors.CYAN}èŒèŒçš„æœ¬åœ°åŒ–æ¼«ç”»å°è¯´è‡ªåŠ¨ç®¡ç†ç³»ç»Ÿ{Colors.RESET}")

    def _cmd_names(self):
        return sorted(
            {
                n[3:]
                for n in dir(self)
                if n.startswith("do_") and len(n) > 3 and n[3:].isidentifier()
            }
        )

    def _safe_split(self, s):
        try:
            return shlex.split(s)
        except Exception:
            return str(s).split()

    def do_help(self, arg):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯: help [å‘½ä»¤]"""
        if arg:
            name = (str(arg).strip().split() or [""])[0]
            if name:
                method = getattr(self, f"do_{name}", None)
                doc = getattr(method, "__doc__", None) if method else None
                if doc:
                    cmd_names = set(self._cmd_names())

                    def paint(color, text, bold=False):
                        if text == "":
                            return text
                        if bold:
                            return f"{Colors.BOLD}{color}{text}{Colors.RESET}"
                        return f"{color}{text}{Colors.RESET}"

                    def paint_cmd(m):
                        w = m.group(0)
                        return paint(Colors.GREEN, w, bold=True)

                    def paint_opt(m):
                        return paint(Colors.YELLOW, m.group(0), bold=False)

                    def paint_placeholder(m):
                        inner = m.group(1)
                        if inner == "å‘½ä»¤":
                            inner2 = paint(Colors.HEADER, inner, bold=True)
                            return f"{Colors.CYAN}<{Colors.RESET}{inner2}{Colors.CYAN}>{Colors.RESET}"
                        return paint(Colors.CYAN, f"<{inner}>")

                    def paint_quoted(m):
                        return paint(Colors.HEADER, m.group(0))

                    def colorize_line(line):
                        raw = line.rstrip("\n")
                        if not raw.strip():
                            return raw

                        stripped = raw.lstrip()
                        indent = raw[: len(raw) - len(stripped)]

                        head_keys = (
                            "å¯¼å…¥æ–‡ä»¶",
                            "å¯¼å‡ºä¹¦ç±",
                            "ä»ç½‘ç»œä¸‹è½½ä¹¦ç±",
                            "å¸¸ç”¨",
                            "æ‰©å±•ç”¨æ³•",
                            "æ”¯æŒæ ¼å¼",
                            "å‘½åæ ¼å¼",
                            "æ¨¡å¼",
                            "ç¤ºä¾‹",
                            "é€‰æ‹©å™¨æ”¯æŒ",
                            "é€‰é¡¹",
                            "æ³¨æ„",
                            "ä¾¿æ·",
                            "åŠŸèƒ½",
                            "æ”¯æŒç«™ç‚¹",
                            "é€šç”¨ä¸‹è½½",
                            "é»˜è®¤(å®‰å…¨æ¨¡å¼)",
                            "ä¿®å¤æ¨¡å¼",
                            "èŒƒå›´å‚æ•°",
                        )
                        if any(stripped.startswith(k) for k in head_keys):
                            if ":" in stripped or "ï¼š" in stripped:
                                sep = ":" if ":" in stripped else "ï¼š"
                                left, right = stripped.split(sep, 1)
                                left2 = paint(Colors.BLUE, left + sep, bold=True)
                                stripped = left2 + " " + right.lstrip()
                            else:
                                stripped = paint(Colors.BLUE, stripped, bold=True)

                        stripped = re.sub(r'"[^"\\]*(?:\\.[^"\\]*)*"', paint_quoted, stripped)
                        stripped = re.sub(r"<([^>]+)>", paint_placeholder, stripped)
                        stripped = re.sub(r"--[A-Za-z0-9][A-Za-z0-9-]*", paint_opt, stripped)

                        for w in sorted(cmd_names, key=len, reverse=True):
                            stripped = re.sub(rf"\b{re.escape(w)}\b", paint_cmd, stripped)

                        stripped = re.sub(
                            r"^(\s*)(\d+\))",
                            lambda m: m.group(1) + paint(Colors.YELLOW, m.group(2), bold=True),
                            stripped,
                        )
                        stripped = re.sub(
                            r"^(\s*)(-)(\s+)",
                            lambda m: m.group(1) + paint(Colors.CYAN, m.group(2), bold=True) + m.group(3),
                            stripped,
                        )
                        stripped = re.sub(
                            r"^(\s*)(\*)(\s+)",
                            lambda m: m.group(1) + paint(Colors.CYAN, m.group(2), bold=True) + m.group(3),
                            stripped,
                        )

                        return indent + stripped

                    text = doc.strip("\n")
                    print(paint(Colors.BLUE, f"\nğŸ“˜ {name} å¸®åŠ©", bold=True))
                    for ln in text.splitlines():
                        print(colorize_line(ln))
                    print("")
                    return

                cmd_names = self._cmd_names()
                close = difflib.get_close_matches(name, cmd_names, n=5, cutoff=0.4)
                print(Colors.red(f"æ‰¾ä¸åˆ°å‘½ä»¤: {name} å–µ..."))
                if close:
                    print(Colors.cyan("ä½ æ˜¯ä¸æ˜¯æƒ³è¾“å…¥:"))
                    print("  " + "  ".join(Colors.green(c) for c in close))
                    hint = close[0]
                    if hint == "help":
                        print(Colors.cyan("è¯•è¯•: help"))
                    else:
                        print(Colors.cyan(f"è¯•è¯•: help {hint}"))
                else:
                    print(Colors.cyan("è¾“å…¥ help æŸ¥çœ‹å‘½ä»¤åˆ—è¡¨å–µ~"))
                return

            super().do_help(arg)
            return

        def cmd(name, width=10):
            return Colors.green(f"{name:<{width}}")

        def section(title):
            return f"{Colors.BLUE}{Colors.BOLD}{title}{Colors.RESET}"

        def dim(text):
            return f"{Colors.CYAN}{text}{Colors.RESET}"

        print(f"\n{Colors.BOLD}{Colors.CYAN}ğŸ“– {Colors.HEADER}èŒèŒ{Colors.CYAN}çš„ä½¿ç”¨æŒ‡å— ğŸ“–{Colors.RESET}")
        print(dim("å‘½ä»¤åˆ—è¡¨å–µï¼š"))
        print(Colors.cyan("â”€" * 44))

        print(f"\n{section('ğŸ“š è—ä¹¦ç®¡ç†')}")
        print(f"  {cmd('import')}  {Colors.yellow('å¯¼å…¥ä¹¦ç±')}  {dim('(å¤šç§å‘½åæ ¼å¼/æ–‡ä»¶å¤¹/é¢„è§ˆ/åˆ æºæ–‡ä»¶)')}")
        print(f"  {cmd('download')} {Colors.yellow('ä¸‹è½½/çˆ¬è™«')}  {dim('(æ”¯æŒPixiv/é€šç”¨ä¸‹è½½/è‡ªåŠ¨å½’æ¡£)')}")
        print(f"  {cmd('export')}   {Colors.yellow('å¯¼å‡ºä¹¦ç±')}  {dim('(æ”¯æŒæ‰¹é‡/ç­›é€‰/zip)')}")
        print(f"  {cmd('list')}     {Colors.yellow('åˆ—å‡ºæ‰€æœ‰è—ä¹¦')}")
        print(f"  {cmd('authors')}  {Colors.yellow('åˆ—å‡ºæ‰€æœ‰ä½œè€…')}  {dim('(æ”¯æŒæœç´¢/è—ä¹¦ç»Ÿè®¡)')}")
        print(f"  {cmd('search')}   {Colors.yellow('æœç´¢ä¹¦ç±')}  {dim('(æ”¯æŒæ¨¡ç³Šæœç´¢ & é«˜çº§è¿‡æ»¤)')}")
        print(f"  {cmd('delete')}   {Colors.yellow('åˆ é™¤ä¹¦ç±')}  {dim('(æ–‡ä»¶å’Œè®°å½•)')}")
        print(f"  {cmd('update')}   {Colors.yellow('ä¿®æ”¹ä¹¦ç±ä¿¡æ¯')}  {dim('(æ”¯æŒæ‰¹é‡/ç­›é€‰/ids/è‡ªåŠ¨ç§»åŠ¨)')}")

        print(f"\n{section('ğŸ”§ ç³»ç»Ÿç»´æŠ¤')}")
        print(f"  {cmd('stats')}    {Colors.yellow('æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯')}")
        print(f"  {cmd('clean')}    {Colors.yellow('æ¸…ç†å¹¶å¯åŒæ­¥è—ä¹¦ç›®å½•')}  {dim('(è¡¥å½•/çº æ­£è·¯å¾„/åˆ éæ³•)')}")
        print(f"  {cmd('optimize')} {Colors.yellow('ä¼˜åŒ–æ•°æ®åº“')}  {dim('(é‡æ’ID/å¡«è¡¥ç©ºç¼º/å‹ç¼©ä½“ç§¯)')}")
        print(f"  {cmd('reset')}    {Colors.yellow('é‡ç½®ç³»ç»Ÿ')}  {dim('(æ¸…ç©ºæ‰€æœ‰æ•°æ®/æ…ç”¨)')}")
        print(f"  {cmd('clear')}    {Colors.yellow('æ¸…ç©ºå±å¹•')}  {dim('(ç„•ç„¶ä¸€æ–°å–µ)')}")
        print(f"  {cmd('help')}     {Colors.yellow('æ˜¾ç¤ºè¿™ä¸ªå¸®åŠ©èœå•')}")
        print(f"  {cmd('exit')}     {Colors.yellow('é€€å‡ºç³»ç»Ÿ')}")

        print(Colors.cyan("â”€" * 44))
        tip = (
            f"{Colors.YELLOW}ğŸ’¡ æç¤º:{Colors.RESET} "
            f"{Colors.CYAN}è¾“å…¥{Colors.RESET} "
            f"{Colors.BOLD}{Colors.GREEN}help{Colors.RESET} "
            f"{Colors.CYAN}<{Colors.HEADER}å‘½ä»¤{Colors.CYAN}>{Colors.RESET} "
            f"{Colors.CYAN}æŸ¥çœ‹è¯¦ç»†ç”¨æ³•å–µ~{Colors.RESET}"
        )
        print(tip)
        print(
            f"{Colors.CYAN}ä¾‹å¦‚:{Colors.RESET} "
            f"{Colors.BOLD}{Colors.GREEN}help{Colors.RESET} {Colors.HEADER}import{Colors.RESET}"
            f"{Colors.CYAN}  æˆ–  {Colors.RESET}"
            f"{Colors.BOLD}{Colors.GREEN}help{Colors.RESET} {Colors.HEADER}export{Colors.RESET}"
        )
        print(
            f"{Colors.YELLOW}ğŸ’¡ å°æŠ€å·§:{Colors.RESET} "
            f"{Colors.CYAN}æŒ‰{Colors.RESET} {Colors.BOLD}{Colors.GREEN}Tab{Colors.RESET} "
            f"{Colors.CYAN}å¯è‡ªåŠ¨è¡¥å…¨ ID/å­—æ®µ/é€‰é¡¹å–µ~{Colors.RESET}"
        )
        print(
            f"{Colors.YELLOW}ğŸ’¡ å°æŠ€å·§:{Colors.RESET} "
            f"{Colors.CYAN}è·¯å¾„å«ç©ºæ ¼æ—¶ç”¨å¼•å·åŒ…ä½ï¼Œä¾‹å¦‚:{Colors.RESET} "
            f"{Colors.BOLD}{Colors.GREEN}import{Colors.RESET} {Colors.HEADER}\"/path/with space/a.txt\"{Colors.RESET}"
        )
        print(
            f"{Colors.YELLOW}ğŸ’¡ å°æŠ€å·§:{Colors.RESET} "
            f"{Colors.CYAN}ä¹Ÿå¯ä»¥ç›´æ¥ç²˜è´´è·¯å¾„æ¥å¯¼å…¥ï¼Œä¾‹å¦‚:{Colors.RESET} "
            f"{Colors.HEADER}/path/to/book.txt{Colors.RESET}"
        )
        print("")

    def complete_help(self, text, line, begidx, endidx):
        return [c for c in self._cmd_names() if c.startswith(text)]

    def emptyline(self):
        return

    def default(self, line):
        raw = (line or "").strip()
        if not raw:
            return

        if hasattr(self, "do_import"):
            try:
                expanded = os.path.expanduser(os.path.expandvars(raw))
            except Exception:
                expanded = raw

            try:
                if expanded and os.path.exists(expanded):
                    self.do_import(expanded)
                    return
            except Exception:
                pass

            tokens2 = self._safe_split(raw)
            if tokens2:
                first = tokens2[0]
                try:
                    first2 = os.path.expanduser(os.path.expandvars(first))
                except Exception:
                    first2 = first
                try:
                    if first2 and os.path.exists(first2):
                        tokens2[0] = first2
                        rebuilt = " ".join(shlex.quote(t) for t in tokens2)
                        self.do_import(rebuilt)
                        return
                except Exception:
                    pass

        tokens = self._safe_split(raw)
        if not tokens:
            return
        name = tokens[0]
        cmd_names = self._cmd_names()
        close = difflib.get_close_matches(name, cmd_names, n=5, cutoff=0.4)
        print(Colors.red(f"æœªçŸ¥å‘½ä»¤: {name} å–µ..."))
        if close:
            print(Colors.cyan("ä½ æ˜¯ä¸æ˜¯æƒ³è¾“å…¥:"))
            print("  " + "  ".join(Colors.green(c) for c in close))
            hint = close[0]
            if hint == "help":
                print(Colors.cyan("è¯•è¯•: help"))
            else:
                print(Colors.cyan(f"è¯•è¯•: help {hint}"))
        else:
            print(Colors.cyan("è¾“å…¥ help æŸ¥çœ‹å‘½ä»¤åˆ—è¡¨å–µ~"))

    def do_EOF(self, arg):
        """é€€å‡ºç³»ç»Ÿ: Ctrl-D"""
        return True

    def do_clear(self, arg):
        """æ¸…ç©ºå±å¹•: clear"""
        os.system('cls' if os.name == 'nt' else 'clear')
        print(self.intro)

    def do_reset(self, arg):
        """é‡ç½®ç³»ç»Ÿ (æ¸…ç©ºæ‰€æœ‰æ•°æ®): reset [--yes]

        è­¦å‘Š: æ­¤æ“ä½œå°†åˆ é™¤æ•°æ®åº“ä¸­çš„æ‰€æœ‰ä¹¦ç±è®°å½•ã€ä½œè€…è®°å½•ï¼Œ
        å¹¶æ¸…ç©º Library ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼æ— æ³•æ’¤é”€ï¼
        """
        args = arg.split()
        force = "--yes" in args or "-y" in args

        print(Colors.red(f"\n{Colors.BOLD}âš ï¸  å±é™©æ“ä½œè­¦å‘Š âš ï¸{Colors.RESET}"))
        print(Colors.red("å³å°†æ¸…ç©ºæ‰€æœ‰æ•°æ®ï¼ŒåŒ…æ‹¬ï¼š"))
        print(Colors.red("1. æ•°æ®åº“ä¸­çš„æ‰€æœ‰ä¹¦ç±å’Œä½œè€…è®°å½•"))
        print(Colors.red("2. ä¹¦åº“ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ (å®ä½“ä¹¦)"))
        print(Colors.red("æ­¤æ“ä½œä¸å¯æ¢å¤ï¼"))

        if not force:
            confirm = input(Colors.yellow("\nä½ ç¡®å®šè¦è¿™ä¹ˆåšå—ï¼Ÿè¯·è¾“å…¥ 'yes' ç¡®è®¤: ")).strip()
            if confirm.lower() != "yes":
                print(Colors.green("æ“ä½œå·²å–æ¶ˆå–µ~"))
                return

        print(Colors.cyan("\næ­£åœ¨é‡ç½®æ•°æ®åº“..."))
        if self.db.clear_all():
            print(Colors.green("æ•°æ®åº“å·²æ¸…ç©ºå–µï¼"))
        else:
            print(Colors.red("æ•°æ®åº“æ¸…ç©ºå¤±è´¥å–µ..."))

        print(Colors.cyan("æ­£åœ¨æ¸…ç©ºä¹¦åº“æ–‡ä»¶..."))
        if self.fm.clear_library():
            print(Colors.green("ä¹¦åº“æ–‡ä»¶å·²æ¸…ç©ºå–µï¼"))
        else:
            print(Colors.red("ä¹¦åº“æ¸…ç©ºå¤±è´¥å–µ..."))

        print(Colors.green("\nâœ¨ ç³»ç»Ÿå·²é‡ç½®ä¸ºåˆå§‹çŠ¶æ€å–µï¼"))

    def do_clean(self, arg="", silent=False):
        """æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥ä¸ä¿®å¤: clean [--fix] [--yes] [èŒƒå›´]

        é»˜è®¤(å®‰å…¨æ¨¡å¼):
        - æ‰«æå®é™…æ–‡ä»¶(ä»¥æ–‡ä»¶ä¸ºå‡†)ï¼Œç”Ÿæˆå·®å¼‚æŠ¥å‘Šï¼Œä¸åšä»»ä½•ä¿®æ”¹

        ä¿®å¤æ¨¡å¼:
        - ä½¿ç”¨ --fix æ˜¾å¼å¼€å¯
        - è‡ªåŠ¨å¤‡ä»½æ•°æ®åº“
        - ä½¿ç”¨äº‹åŠ¡ä¿è¯åŸå­æ€§
        - è‡ªåŠ¨åˆ é™¤å¤šä½™è®°å½• / è¡¥å½•ç¼ºå¤±è®°å½• / æ›´æ–°ä¸ä¸€è‡´çš„å…ƒæ•°æ®
        - ä¿®å¤åè‡ªåŠ¨å¤æ£€

        èŒƒå›´å‚æ•°:
        - --dir=PATH
        - --type=pdf
        - --since=YYYY-MM-DD / --until=YYYY-MM-DD
        - --resume-from=PATH

        é€‰é¡¹:
        - --fix / --apply
        - --yes / -y
        - --dry-run
        """
        if silent:
            return

        def safe_split(s):
            try:
                return shlex.split((s or "").strip()) if (s or "").strip() else []
            except Exception:
                return str(s or "").split()

        tokens = safe_split(arg)
        yes = ("--yes" in tokens) or ("-y" in tokens)
        fix = ("--fix" in tokens) or ("--apply" in tokens) or ("--repair" in tokens)

        dir_filter = ""
        type_filter = ""
        since_s = ""
        until_s = ""
        resume_from = ""
        for t in tokens:
            if t.startswith("--dir="):
                dir_filter = t.split("=", 1)[1].strip()
            elif t.startswith("--type="):
                type_filter = t.split("=", 1)[1].strip().lstrip(".")
            elif t.startswith("--ext="):
                type_filter = t.split("=", 1)[1].strip().lstrip(".")
            elif t.startswith("--since="):
                since_s = t.split("=", 1)[1].strip()
            elif t.startswith("--until="):
                until_s = t.split("=", 1)[1].strip()
            elif t.startswith("--resume-from="):
                resume_from = t.split("=", 1)[1].strip()

        logger = get_logger()

        try:
            lib_root_obj = getattr(self.fm, "library_dir", "library")
            lib_root = os.path.abspath(str(lib_root_obj))
        except Exception:
            lib_root = os.path.abspath("library")

        scope_root = lib_root
        if dir_filter:
            try:
                expanded = os.path.expanduser(os.path.expandvars(dir_filter))
            except Exception:
                expanded = dir_filter
            if not os.path.isabs(expanded):
                scope_root = os.path.abspath(os.path.join(lib_root, expanded))
            else:
                scope_root = os.path.abspath(expanded)

        if not os.path.exists(scope_root):
            print(Colors.red(f"æ‰¾ä¸åˆ°ç›®å½•å–µ: {scope_root}"))
            return

        supported_exts = set(getattr(self, "_IMPORT_EXTS", {".txt", ".pdf", ".doc", ".docx", ".epub", ".cbz", ".zip"}))
        supported_exts = {("." + str(e).lstrip(".")) if e else e for e in supported_exts}
        type_ext = ("." + type_filter.lower().lstrip(".")) if type_filter else ""

        def parse_dt(s, end=False):
            s = (s or "").strip()
            if not s:
                return None
            try:
                if len(s) == 10 and "T" not in s and ":" not in s:
                    d = datetime.datetime.fromisoformat(s)
                    if end:
                        d = d + datetime.timedelta(days=1) - datetime.timedelta(seconds=1)
                    return d
                return datetime.datetime.fromisoformat(s)
            except Exception:
                return None

        since_dt = parse_dt(since_s, end=False)
        until_dt = parse_dt(until_s, end=True)
        since_ts = since_dt.timestamp() if since_dt else None
        until_ts = until_dt.timestamp() if until_dt else None

        def abs_norm(p):
            try:
                return os.path.normpath(os.path.abspath(str(p)))
            except Exception:
                return os.path.normpath(str(p))

        def under_root(root, p):
            root = abs_norm(root)
            p = abs_norm(p)
            try:
                return os.path.commonpath([root, p]) == root
            except Exception:
                return False

        def iter_files(root_path):
            if os.path.isfile(root_path):
                yield root_path
                return
            for r, _, files2 in os.walk(root_path):
                for name in files2:
                    yield os.path.join(r, name)

        eng = ImportEngine(self.db, self.fm, import_exts=supported_exts)
        hash_cache = {}

        def file_hash(fp):
            k = abs_norm(fp)
            if k in hash_cache:
                return hash_cache[k]
            h = eng.file_hash(k)
            hash_cache[k] = h
            return h

        file_infos = {}
        file_lookup = {}
        illegal_files = []

        try:
            cwd = os.path.abspath(os.getcwd())
        except Exception:
            cwd = ""

        scanned = 0
        for fp in iter_files(scope_root):
            scanned += 1
            base = os.path.basename(fp)
            if base.startswith("."):
                illegal_files.append(fp)
                continue
            ext = os.path.splitext(base)[1].lower()
            if ext not in supported_exts:
                illegal_files.append(fp)
                continue
            if type_ext and ext != type_ext:
                continue
            try:
                st = os.stat(fp)
            except PermissionError as e:
                print(Colors.red(f"æƒé™ä¸è¶³ï¼Œæ— æ³•è¯»å–æ–‡ä»¶å–µ: {fp} ({e})"))
                continue
            except OSError as e:
                print(Colors.red(f"è¯»å–æ–‡ä»¶å¤±è´¥å–µ: {fp} ({e})"))
                continue

            mtime = float(st.st_mtime)
            if since_ts is not None and mtime < since_ts:
                continue
            if until_ts is not None and mtime > until_ts:
                continue

            ap = abs_norm(fp)
            info = {"path": ap, "size": int(st.st_size), "mtime": float(st.st_mtime), "ext": ext}
            file_infos[ap] = info

            cands = set()
            cands.add(ap)
            cands.add(os.path.normpath(fp))
            try:
                if cwd:
                    rel_cwd = os.path.relpath(ap, cwd)
                    cands.add(rel_cwd)
                    cands.add(os.path.normpath(rel_cwd))
            except Exception:
                pass
            for c in cands:
                if c and c not in file_lookup:
                    file_lookup[c] = ap

            if scanned % 500 == 0:
                print(Colors.cyan(f"å·²æ‰«æ {scanned} ä¸ªæ–‡ä»¶å–µ..."))

        if resume_from:
            rf = abs_norm(resume_from)
            if rf in file_infos:
                started = False
                new_infos = {}
                for k in sorted(file_infos.keys()):
                    if (not started) and k == rf:
                        started = True
                    if started:
                        new_infos[k] = file_infos[k]
                file_infos = new_infos

        try:
            books_all = list(self.db.list_books() or [])
        except Exception:
            books_all = []

        books = []
        for b in books_all:
            try:
                fp = b["file_path"]
            except Exception:
                fp = ""
            if not fp:
                continue
            ap = abs_norm(fp)
            if under_root(scope_root, ap):
                books.append(b)

            if os.path.exists(fp):
                ap2 = abs_norm(fp)
                if ap2 not in file_infos:
                    try:
                        st = os.stat(fp)
                        file_infos[ap2] = {"path": ap2, "size": int(st.st_size), "mtime": float(st.st_mtime), "ext": os.path.splitext(fp)[1].lower()}
                    except Exception:
                        pass
                if fp and fp not in file_lookup:
                    file_lookup[fp] = ap2
                np2 = os.path.normpath(fp)
                if np2 and np2 not in file_lookup:
                    file_lookup[np2] = ap2
                try:
                    if cwd:
                        rel_cwd = os.path.relpath(ap2, cwd)
                        if rel_cwd not in file_lookup:
                            file_lookup[rel_cwd] = ap2
                        rel2 = os.path.normpath(rel_cwd)
                        if rel2 not in file_lookup:
                            file_lookup[rel2] = ap2
                except Exception:
                    pass

        db_by_file = {}
        db_by_id = {}
        for b in books:
            try:
                bid = int(b["id"])
            except Exception:
                continue
            db_by_id[bid] = b
            try:
                fp = b["file_path"]
            except Exception:
                fp = ""
            if not fp:
                continue
            canon = file_lookup.get(fp) or file_lookup.get(os.path.normpath(fp)) or file_lookup.get(abs_norm(fp))
            if not canon:
                canon = abs_norm(fp)
            db_by_file.setdefault(canon, []).append(b)

        missing_files_records = []
        relink_records = []
        duplicates_records = []
        missing_db_records = []
        meta_mismatches = []

        size_index = {}
        for ap, info in file_infos.items():
            size_index.setdefault(int(info.get("size") or 0), []).append(ap)

        for ap, b_list in db_by_file.items():
            if len(b_list) > 1:
                ids = []
                for b in b_list:
                    try:
                        ids.append(int(b["id"]))
                    except Exception:
                        pass
                if ids:
                    duplicates_records.append({"path": ap, "ids": sorted(ids)})

        for bid, b in db_by_id.items():
            fp = ""
            try:
                fp = b["file_path"]
            except Exception:
                fp = ""
            if not fp:
                continue

            if os.path.exists(fp):
                canon = file_lookup.get(fp) or file_lookup.get(os.path.normpath(fp)) or file_lookup.get(abs_norm(fp))
                if not canon:
                    canon = abs_norm(fp)
                info = file_infos.get(canon)
                if not info:
                    continue

                db_size = None
                db_mtime = None
                db_hash = ""
                try:
                    if "file_size" in b.keys():
                        db_size = b["file_size"]
                except Exception:
                    db_size = None
                try:
                    if "file_mtime" in b.keys():
                        db_mtime = b["file_mtime"]
                except Exception:
                    db_mtime = None
                try:
                    db_hash = (b["file_hash"] if "file_hash" in b.keys() else "") or ""
                except Exception:
                    db_hash = ""

                need_size = (db_size is None) or (int(db_size) != int(info.get("size") or 0))
                need_mtime = (db_mtime is None) or (abs(float(db_mtime) - float(info.get("mtime") or 0.0)) > 1.0)
                need_hash = False
                new_hash = ""
                if db_hash:
                    new_hash = file_hash(canon)
                    if new_hash and new_hash != db_hash:
                        need_hash = True
                else:
                    new_hash = file_hash(canon)
                    if new_hash:
                        need_hash = True

                if need_size or need_mtime or need_hash:
                    meta_mismatches.append(
                        {
                            "id": bid,
                            "path": canon,
                            "need_hash": need_hash,
                            "new_hash": new_hash,
                            "size": int(info.get("size") or 0),
                            "mtime": float(info.get("mtime") or 0.0),
                        }
                    )
                continue

            fh = ""
            try:
                fh = (b["file_hash"] if "file_hash" in b.keys() else "") or ""
            except Exception:
                fh = ""
            fsz = None
            try:
                if "file_size" in b.keys():
                    fsz = b["file_size"]
            except Exception:
                fsz = None

            if fh:
                candidates = []
                if fsz is not None:
                    candidates = list(size_index.get(int(fsz), []))
                if not candidates:
                    candidates = list(file_infos.keys())
                found = ""
                for cand in candidates[:500]:
                    if file_hash(cand) == fh:
                        found = cand
                        break
                if found:
                    relink_records.append({"id": bid, "old": fp, "new": found, "hash": fh})
                else:
                    missing_files_records.append({"id": bid, "path": fp})
            else:
                missing_files_records.append({"id": bid, "path": fp})

        for ap in sorted(file_infos.keys()):
            if ap not in db_by_file:
                missing_db_records.append({"path": ap})

        print(Colors.cyan("\nğŸ“¦ å®Œæ•´æ€§æŠ¥å‘Š(ä»¥å®é™…æ–‡ä»¶ä¸ºå‡†)"))
        print(Colors.cyan(f"  èŒƒå›´: {scope_root}"))
        if type_ext:
            print(Colors.cyan(f"  ç±»å‹: {type_ext.lstrip('.')}"))
        if since_dt:
            print(Colors.cyan(f"  èµ·å§‹: {since_dt.strftime('%Y-%m-%d %H:%M:%S')}"))
        if until_dt:
            print(Colors.cyan(f"  æˆªæ­¢: {until_dt.strftime('%Y-%m-%d %H:%M:%S')}"))

        print(Colors.yellow("\né—®é¢˜æ±‡æ€»:"))
        print(f"  - æ•°æ®åº“å¤šä½™è®°å½•(æ–‡ä»¶ç¼ºå¤±): {len(missing_files_records)}")
        print(f"  - æ•°æ®åº“ç¼ºå¤±è®°å½•(æ–‡ä»¶æœªå…¥åº“): {len(missing_db_records)}")
        print(f"  - å¯è‡ªåŠ¨çº æ­£è·¯å¾„(é  hash æ‰¾å›): {len(relink_records)}")
        print(f"  - æŒ‡å‘åŒä¸€æ–‡ä»¶çš„é‡å¤è®°å½•: {len(duplicates_records)}")
        print(f"  - å…ƒæ•°æ®ä¸ä¸€è‡´(å¤§å°/æ—¶é—´/hash): {len(meta_mismatches)}")
        if illegal_files:
            print(f"  - éæ³•/å¿½ç•¥æ–‡ä»¶: {len(illegal_files)}")

        def show(label, items, fmt):
            if not items:
                return
            print(Colors.yellow(f"\n{label} (å±•ç¤ºå‰ 10 æ¡):"))
            for x in items[:10]:
                print(fmt(x))
            if len(items) > 10:
                print(Colors.cyan(f"  ... è¿˜æœ‰ {len(items) - 10} æ¡"))

        show("æ•°æ®åº“å¤šä½™è®°å½•", missing_files_records, lambda x: f"  - [{x['id']}] {x['path']}")
        show("æ•°æ®åº“ç¼ºå¤±è®°å½•", missing_db_records, lambda x: f"  - {x['path']}")
        show("å¯çº æ­£è·¯å¾„", relink_records, lambda x: f"  - [{x['id']}] {x['old']} -> {x['new']}")
        show("é‡å¤è®°å½•", duplicates_records, lambda x: f"  - {x['path']}  ids={','.join(str(i) for i in x['ids'])}")
        show("å…ƒæ•°æ®ä¸ä¸€è‡´", meta_mismatches, lambda x: f"  - [{x['id']}] {x['path']}")

        if (not fix) or ("--dry-run" in tokens):
            if not fix:
                total_issues = (
                    len(missing_files_records)
                    + len(missing_db_records)
                    + len(relink_records)
                    + len(duplicates_records)
                    + len(meta_mismatches)
                )
                if total_issues > 0:
                    print(Colors.cyan("\nå»ºè®®: clean --fix --yes è¿›è¡Œè‡ªåŠ¨ä¿®å¤å–µ"))
                else:
                    if illegal_files:
                        print(Colors.green("\næ•°æ®åº“çŠ¶æ€å®Œç¾å–µï¼(è™½ç„¶æœ‰ä¸€äº›æœªæ”¶å½•çš„æ–‡ä»¶/éæ³•æ–‡ä»¶)"))
                    else:
                        print(Colors.green("\nå¤ªæ£’äº†å–µï¼ä¹¦åº“éå¸¸å®Œç¾ï¼Œæ²¡æœ‰ä»»ä½•é—®é¢˜å–µ~"))
            return

        if not yes:
            print(Colors.red("\nâš ï¸  ä¿®å¤æ¨¡å¼ä¼šä¿®æ”¹æ•°æ®åº“å–µï¼"))
            ans = input(Colors.cyan("ç¡®è®¤ç»§ç»­å—ï¼Ÿè¯·è¾“å…¥ yes: ")).strip().lower()
            if ans != "yes":
                print(Colors.green("æ“ä½œå·²å–æ¶ˆå–µã€‚"))
                return

        db_path = ""
        try:
            db_path = str(getattr(self.db, "db_path", "") or "")
        except Exception:
            db_path = ""
        if not db_path:
            print(Colors.red("æ‰¾ä¸åˆ°æ•°æ®åº“è·¯å¾„å–µ..."))
            return

        ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = f"{db_path}.bak_{ts}"
        try:
            shutil.copy2(db_path, backup_path)
        except Exception as e:
            print(Colors.red(f"æ•°æ®åº“å¤‡ä»½å¤±è´¥å–µ: {e}"))
            return

        try:
            logger.info("clean_backup db=%s backup=%s", db_path, backup_path)
        except Exception:
            pass

        conn = getattr(self.db, "conn", None)
        if conn is None:
            print(Colors.red("æ•°æ®åº“è¿æ¥ä¸å¯ç”¨å–µ..."))
            return

        def infer_from_library_path(ap):
            author = "ä½šå"
            series = ""
            try:
                if under_root(lib_root, ap):
                    rel = os.path.relpath(ap, lib_root)
                    parts = [p for p in rel.split(os.sep) if p and p not in {".", ".."}]
                    if len(parts) >= 2:
                        author = parts[0].strip() or author
                    if len(parts) >= 3:
                        series = os.sep.join(parts[1:-1]).strip(os.sep)
            except Exception:
                pass
            return author, series

        try:
            self.db._suspend_commit = True
        except Exception:
            pass

        last_fp = ""
        try:
            conn.execute("BEGIN")

            del_dup = 0
            keep_ids = set()
            for item in duplicates_records:
                ids = list(item.get("ids") or [])
                if ids:
                    keep_ids.add(max(ids))
            for item in duplicates_records:
                ids = list(item.get("ids") or [])
                if len(ids) <= 1:
                    continue
                keep = max(ids)
                for bid in ids:
                    if bid == keep:
                        continue
                    last_fp = str(item.get("path") or "")
                    if self.db.delete_book(int(bid)):
                        del_dup += 1
                        try:
                            logger.info("clean_delete_duplicate book_id=%s keep_id=%s", bid, keep)
                        except Exception:
                            pass

            del_orphan = 0
            for item in missing_files_records:
                bid = int(item["id"])
                if bid in keep_ids:
                    continue
                last_fp = str(item.get("path") or "")
                if self.db.delete_book(bid):
                    del_orphan += 1
                    try:
                        logger.info("clean_delete_orphan book_id=%s", bid)
                    except Exception:
                        pass

            relinked = 0
            for item in relink_records:
                bid = int(item["id"])
                newp = str(item["new"])
                last_fp = newp
                if self.db.update_book(bid, file_path=newp):
                    relinked += 1
                    try:
                        logger.info("clean_relink book_id=%s new_path=%s", bid, newp)
                    except Exception:
                        pass

            updated_meta = 0
            for item in meta_mismatches:
                bid = int(item["id"])
                fp = str(item["path"])
                last_fp = fp
                upd = {"file_size": int(item.get("size") or 0), "file_mtime": float(item.get("mtime") or 0.0)}
                if item.get("need_hash") and item.get("new_hash"):
                    upd["file_hash"] = str(item.get("new_hash"))
                if self.db.update_book(bid, **upd):
                    updated_meta += 1
                    try:
                        logger.info("clean_update_meta book_id=%s path=%s", bid, fp)
                    except Exception:
                        pass

            added = 0
            now_s = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            reserved = set()
            for item in relink_records:
                try:
                    reserved.add(str(item.get("new") or ""))
                except Exception:
                    pass
            for p in list(db_by_file.keys()):
                try:
                    if p and os.path.exists(p):
                        reserved.add(str(p))
                except Exception:
                    pass
            for item in missing_db_records:
                fp = str(item["path"])
                if fp in reserved:
                    continue
                last_fp = fp
                meta = eng.parse_metadata_from_filename(fp) or {}
                title = (meta.get("title") or os.path.splitext(os.path.basename(fp))[0]).strip()
                author = (meta.get("author") or "").strip()
                series = (meta.get("series") or "").strip()
                if not author or author == "ä½šå":
                    a2, s2 = infer_from_library_path(fp)
                    if (not author) or author == "ä½šå":
                        author = a2
                    if not series:
                        series = s2
                if not author:
                    author = "ä½šå"
                if not title:
                    title = "æœªå‘½å"
                ext2 = os.path.splitext(fp)[1].lower().lstrip(".")
                fh2 = file_hash(fp)
                self.db.add_book(title, author, "", 0, series, fp, ext2, file_hash=fh2, import_date=now_s)
                added += 1
                try:
                    logger.info("clean_add_missing file=%s title=%s author=%s", fp, title, author)
                except Exception:
                    pass

            conn.commit()
            print(Colors.green(f"\nä¿®å¤å®Œæˆå–µï¼åˆ é™¤å¤šä½™è®°å½•: {del_orphan}ï¼Œåˆå¹¶é‡å¤: {del_dup}ï¼Œçº æ­£è·¯å¾„: {relinked}ï¼Œè¡¥å½•: {added}ï¼Œæ›´æ–°å…ƒæ•°æ®: {updated_meta}"))

        except KeyboardInterrupt:
            try:
                conn.rollback()
            except Exception:
                pass
            print(Colors.red("\næ“ä½œè¢«ä¸­æ–­å–µï¼Œå·²å›æ»šæœ¬æ¬¡æ›´æ”¹ã€‚"))
            if last_fp:
                print(Colors.cyan(f"å¯ç”¨ --resume-from={shlex.quote(last_fp)} ç»§ç»­å–µ"))
            try:
                logger.info("clean_interrupted last=%s", last_fp)
            except Exception:
                pass
            return
        except Exception as e:
            try:
                conn.rollback()
            except Exception:
                pass
            print(Colors.red(f"\nä¿®å¤å¤±è´¥ï¼Œå·²å›æ»šå–µ: {e}"))
            try:
                logger.info("clean_failed error=%s", str(e))
            except Exception:
                pass
            return

        finally:
            try:
                self.db._suspend_commit = False
            except Exception:
                pass

        print(Colors.cyan("\nå¼€å§‹å¤æ£€å–µ..."))
        try:
            verify_tokens = [x for x in tokens if x not in {"--fix", "--apply", "--repair"}]
            verify_tokens.append("--dry-run")
            verify_arg = " ".join(shlex.quote(x) for x in verify_tokens)
            self.do_clean(verify_arg, silent=False)
        except Exception:
            pass

    def do_clean_legacy(self, arg="", silent=False):
        """æ¸…ç†æ— æ•ˆè®°å½•: clean [--sync] [--dry-run] [--yes]

        é»˜è®¤è¡Œä¸º(ä¸å¸¦å‚æ•°):
        1) ç§»é™¤æ–‡ä»¶ä¸å­˜åœ¨çš„è®°å½•
        2) ç§»é™¤æ ‡é¢˜ä»¥ . å¼€å¤´çš„éæ³•ä¹¦ç±è®°å½•
        3) åˆå¹¶æŒ‡å‘åŒä¸€æ–‡ä»¶çš„é‡å¤è®°å½•ï¼ˆä¿ç•™ ID æœ€å¤§çš„ï¼‰

        åŒæ­¥æ¨¡å¼(clean --sync):
        - æ‰«æ library/ ä¸‹çš„æ–‡ä»¶ï¼Œè¡¥å½•æ•°æ®åº“ç¼ºå¤±çš„è®°å½•
        - è¡¥é½ file_hashï¼Œå¹¶å°è¯•ç”¨ hash æ‰¾å›æ¬å®¶/æ”¹åçš„æ–‡ä»¶
        - éæ³•æ–‡ä»¶(ä¸æ”¯æŒåç¼€æˆ–ä»¥ . å¼€å¤´)ä¼šè‡ªåŠ¨åˆ é™¤(å¯ç”¨ --keep-illegal ä¿ç•™)

        é€‰é¡¹:
        - --sync / --scan : åŒæ­¥è—ä¹¦ç›®å½•åˆ°æ•°æ®åº“
        - --dry-run       : ä»…é¢„è§ˆï¼Œä¸åšä»»ä½•å†™å…¥/åˆ é™¤
        - --yes / -y      : è·³è¿‡ç¡®è®¤ï¼Œç›´æ¥æ‰§è¡Œ
        - --keep-illegal  : åŒæ­¥æ—¶ä¿ç•™éæ³•æ–‡ä»¶(é»˜è®¤ä¼šè‡ªåŠ¨åˆ é™¤)

        ç¤ºä¾‹:
        1) clean                  (ä»…æ¸…ç†æ•°æ®åº“æ— æ•ˆè®°å½•)
        2) clean --sync           (åŒæ­¥ç›®å½• + æ¸…ç†æ•°æ®åº“ï¼Œéœ€ç¡®è®¤)
        3) clean --sync --yes     (åŒæ­¥ + æ¸…ç†ï¼Œä¸è¯¢é—®)
        4) clean --sync --dry-run (ä»…æŸ¥çœ‹åŒæ­¥ä¼šåšä»€ä¹ˆ)
        """
        tokens = []
        try:
            tokens = shlex.split((arg or "").strip()) if (arg or "").strip() else []
        except Exception:
            tokens = []

        token0 = str(tokens[0]).strip().lower() if tokens else ""
        sync_lib = ("--sync" in tokens) or ("--scan" in tokens) or (token0 in {"sync", "scan"})
        dry_run = "--dry-run" in tokens
        yes = ("--yes" in tokens) or ("--force" in tokens) or ("-y" in tokens)
        illegal_mode = "always"
        if "--delete-illegal" in tokens:
            illegal_mode = "always"
        if "--keep-illegal" in tokens:
            illegal_mode = "keep"

        if silent:
            sync_lib = False

        tag_prefixes = ("ã€å°è¯´+æ¼«ç”»ã€‘", "ã€å°è¯´ã€‘", "ã€æ¼«ç”»ã€‘")

        def strip_tag_prefix(name):
            s = "" if name is None else str(name)
            for p in tag_prefixes:
                if s.startswith(p):
                    return s[len(p) :].lstrip()
            return s

        books = list(self.db.list_books() or [])
        if (not books) and (not sync_lib):
            if not silent:
                print(Colors.yellow("è—ä¹¦é˜æ˜¯ç©ºçš„ï¼Œä¸éœ€è¦æ¸…ç†å–µ~"))
            return

        if not silent:
            print(Colors.cyan("æ­£åœ¨æ‰«æä¹¦æ¶å–µ..."))

        removed_count = 0
        dedup_count = 0
        illegal_title_count = 0

        valid_books = []
        for book in books:
            try:
                title = str(book['title'] or "").strip()
            except Exception:
                title = ""
            if title.startswith('.'):
                if not silent:
                    print(Colors.yellow(f"å‘ç°éæ³•æ ‡é¢˜ä¹¦ç±: [{book['id']}] {title}"))

                if dry_run:
                    illegal_title_count += 1
                else:
                    if self.db.delete_book(book['id']):
                        if not silent:
                            print(Colors.green("  -> å·²æ¸…é™¤éæ³•è®°å½•"))
                        illegal_title_count += 1
                    else:
                        if not silent:
                            print(Colors.red("  -> æ¸…é™¤å¤±è´¥å–µ..."))
                continue

            file_path = book['file_path']
            if not os.path.exists(file_path):
                if not silent:
                    print(
                        Colors.yellow(
                            f"å‘ç°ä¸¢å¤±çš„ä¹¦ç±: [{book['id']}] {book['title']} (è·¯å¾„: {file_path})"
                        )
                    )
                if dry_run:
                    removed_count += 1
                else:
                    if self.db.delete_book(book['id']):
                        if not silent:
                            print(Colors.green("  -> å·²æ¸…é™¤æ— æ•ˆè®°å½•"))
                        removed_count += 1
                    else:
                        if not silent:
                            print(Colors.red("  -> æ¸…é™¤å¤±è´¥å–µ..."))
            else:
                valid_books.append(book)

        path_map = {}
        for book in valid_books:
            norm_path = os.path.normpath(book['file_path'])
            if norm_path not in path_map:
                path_map[norm_path] = []
            path_map[norm_path].append(book)

        author_fix_count = 0
        for book in valid_books:
            try:
                old_author = book['author'] or "ä½šå"
                new_author = strip_tag_prefix(old_author)
                if new_author != old_author:
                    if dry_run:
                        if not silent:
                            print(Colors.cyan(f"é¢„è§ˆä¿®æ­£ä½œè€…: [{book['id']}] {old_author} -> {new_author}"))
                        author_fix_count += 1
                    else:
                        self.db.update_book(book['id'], author=new_author)
                        if not silent:
                            print(Colors.green(f"å·²ä¿®æ­£ä½œè€…: [{book['id']}] {old_author} -> {new_author}"))
                        author_fix_count += 1
            except Exception:
                pass

        for path, duplicates in path_map.items():
            if len(duplicates) > 1:
                duplicates.sort(key=lambda x: x['id'], reverse=True)
                keep_book = duplicates[0]
                remove_books = duplicates[1:]

                if not silent:
                    print(Colors.yellow(f"å‘ç°é‡å¤è®°å½•: {path}"))
                    print(
                        Colors.cyan(
                            f"  -> ä¿ç•™æœ€æ–°è®°å½•: [{keep_book['id']}] {keep_book['title']}"
                        )
                    )

                for dup in remove_books:
                    if dry_run:
                        dedup_count += 1
                    else:
                        if self.db.delete_book(dup['id']):
                            if not silent:
                                print(
                                    Colors.green(
                                        f"  -> åˆå¹¶å¹¶ç§»é™¤æ—§è®°å½•: [{dup['id']}] {dup['title']}"
                                    )
                                )
                            dedup_count += 1

        if removed_count > 0 or dedup_count > 0 or illegal_title_count > 0 or author_fix_count > 0:
            msg = []
            if removed_count > 0:
                msg.append(f"ç§»é™¤äº† {removed_count} æ¡æ— æ•ˆè®°å½•")
            if illegal_title_count > 0:
                msg.append(f"æ¸…ç†äº† {illegal_title_count} æœ¬éæ³•æ ‡é¢˜ä¹¦ç±")
            if dedup_count > 0:
                msg.append(f"åˆå¹¶äº† {dedup_count} æ¡é‡å¤è®°å½•")
            if author_fix_count > 0:
                msg.append(f"ä¿®æ­£äº† {author_fix_count} ä¸ªä½œè€…å")
            if not silent:
                if dry_run:
                    print(Colors.green(f"æ¸…ç†é¢„è§ˆ: {'ï¼Œ'.join(msg)}å–µï¼"))
                else:
                    print(Colors.green(f"è‡ªåŠ¨æ¸…ç†: {'ï¼Œ'.join(msg)}å–µï¼"))
        elif not silent:
            print(Colors.green("ä¹¦æ¶éå¸¸æ•´æ´ï¼Œæ²¡æœ‰å‘ç°é—®é¢˜å–µï¼"))

        if not sync_lib:
            return

        def abs_norm(p):
            try:
                return os.path.normpath(os.path.abspath(str(p)))
            except Exception:
                return os.path.normpath(str(p))

        try:
            lib_root_obj = getattr(self.fm, "library_dir", "library")
            lib_root = str(lib_root_obj)
        except Exception:
            lib_root = "library"

        if not os.path.isdir(lib_root):
            if not silent:
                print(Colors.red(f"æ‰¾ä¸åˆ°è—ä¹¦ç›®å½•å–µ: {lib_root}"))
            return

        def infer_meta_from_path(fp):
            author = "ä½šå"
            series = ""
            title0 = os.path.splitext(os.path.basename(fp))[0]
            title1, removed = self._strip_trailing_brackets(title0)
            title = title1 or title0
            st = self._infer_status_from_text(removed, default=None)
            status = 0 if st is None else int(st)
            tags = ""
            try:
                rel = os.path.relpath(fp, lib_root)
                parts = [p for p in rel.split(os.sep) if p and p not in {".", ".."}]
                if len(parts) >= 2:
                    author = strip_tag_prefix(parts[0]) or author
                if len(parts) >= 3:
                    series = os.sep.join(parts[1:-1]).strip(os.sep)
            except Exception:
                pass
            return title, author, series, tags, status

        if not silent:
            print(Colors.cyan("å¼€å§‹åŒæ­¥è—ä¹¦ç›®å½•åˆ°æ•°æ®åº“å–µ..."))

        def plan_sync():
            book_by_id = {}
            path_set = set()
            for b in books:
                try:
                    bid = int(b["id"])
                except Exception:
                    continue
                book_by_id[bid] = b
                try:
                    p = b["file_path"]
                except Exception:
                    p = ""
                if p:
                    path_set.add(os.path.normpath(str(p)))
                    path_set.add(abs_norm(p))

            supported_exts = set(getattr(self, "_IMPORT_EXTS", {".txt", ".pdf", ".doc", ".docx", ".epub"}))
            hash_cache = {}

            hash_updates = []
            for bid, b in book_by_id.items():
                fp = ""
                try:
                    fp = b["file_path"]
                except Exception:
                    fp = ""
                if not fp or (not os.path.exists(fp)):
                    continue
                fh0 = ""
                try:
                    fh0 = b["file_hash"] if "file_hash" in b.keys() else ""
                except Exception:
                    fh0 = ""
                if fh0 and str(fh0).strip():
                    continue

                ap = abs_norm(fp)
                if ap in hash_cache:
                    fh = hash_cache.get(ap) or ""
                else:
                    fh = self._file_hash(fp)
                    hash_cache[ap] = fh
                if fh:
                    hash_updates.append((bid, fh))

            relinks = []
            adds = []
            illegal_files = []

            for root, _, files in os.walk(lib_root):
                for name in files:
                    fp = os.path.join(root, name)
                    try:
                        if os.path.islink(fp):
                            continue
                    except Exception:
                        pass

                    if name.startswith('.'):
                        illegal_files.append(fp)
                        continue

                    ext = os.path.splitext(name)[1].lower()
                    if ext not in supported_exts:
                        illegal_files.append(fp)
                        continue

                    fp_norm = os.path.normpath(fp)
                    fp_abs = abs_norm(fp)
                    if (fp_norm in path_set) or (fp_abs in path_set):
                        continue

                    if fp_abs in hash_cache:
                        fh = hash_cache.get(fp_abs) or ""
                    else:
                        fh = self._file_hash(fp)
                        hash_cache[fp_abs] = fh

                    if fh:
                        try:
                            cands = self.db.find_books_by_file_hash(fh, limit=5)
                        except Exception:
                            cands = []
                        if cands:
                            keep = cands[0]
                            kid = None
                            try:
                                kid = int(keep["id"])
                            except Exception:
                                kid = None
                            if kid is not None:
                                old_fp = ""
                                try:
                                    old_fp = keep["file_path"]
                                except Exception:
                                    old_fp = ""
                                if (not old_fp) or (not os.path.exists(old_fp)) or (os.path.normpath(str(old_fp)) != fp_norm):
                                    relinks.append((kid, fp_norm, ext.lstrip("."), fh))
                                    path_set.add(fp_norm)
                                    path_set.add(fp_abs)
                                    continue

                    title, author, series, tags, status = infer_meta_from_path(fp)
                    adds.append((title, author, tags, status, series, fp_norm, ext.lstrip("."), fh))
                    path_set.add(fp_norm)
                    path_set.add(fp_abs)

            return {
                "hash_updates": hash_updates,
                "relinks": relinks,
                "adds": adds,
                "illegal_files": illegal_files,
            }

        plan = plan_sync()
        hash_updates = plan["hash_updates"]
        relinks = plan["relinks"]
        adds = plan["adds"]
        illegal_files = plan["illegal_files"]

        if illegal_files and (not silent):
            print(Colors.yellow(f"å‘ç° {len(illegal_files)} ä¸ªéæ³•æ–‡ä»¶(ä¸æ”¯æŒåç¼€æˆ–ä»¥ . å¼€å¤´)å–µ~"))
            show_n = 30
            for x in illegal_files[:show_n]:
                print(Colors.yellow(f"  - {x}"))
            if len(illegal_files) > show_n:
                print(Colors.cyan(f"... è¿˜æœ‰ {len(illegal_files) - show_n} ä¸ªæœªå±•ç¤ºå–µ"))

        if adds and (not silent):
            print(Colors.cyan(f"å‡†å¤‡è¡¥å½• {len(adds)} æœ¬ä¹¦å–µ:"))
            show_n = 30
            for i, (title, author, tags, status, series, fp_norm, file_type, fh) in enumerate(adds[:show_n]):
                st_s = Colors.green("å®Œç»“") if int(status or 0) == 1 else Colors.pink("è¿è½½")
                series_s = f"  {Colors.cyan('[' + str(series) + ']')}" if str(series or "").strip() else ""
                print(
                    f"  + {Colors.YELLOW}{str(file_type)}{Colors.RESET} "
                    f"[{Colors.yellow(str(i + 1))}] {Colors.BOLD}{title}{Colors.RESET} - {Colors.green(author)} ({st_s}){series_s}"
                )
            if len(adds) > show_n:
                print(Colors.cyan(f"... è¿˜æœ‰ {len(adds) - show_n} æœ¬æœªå±•ç¤ºå–µ"))

        supported_exts2 = set(getattr(self, "_IMPORT_EXTS", {".txt", ".pdf", ".doc", ".docx", ".epub"}))

        def classify_author_dir(dir_path):
            has_doc = False
            has_pdf = False
            for root, _, files in os.walk(dir_path):
                for fname in files:
                    fp = os.path.join(root, fname)
                    try:
                        if os.path.islink(fp):
                            continue
                    except Exception:
                        pass
                    ext = os.path.splitext(fname)[1].lower()
                    if ext not in supported_exts2:
                        continue
                    if ext == ".pdf":
                        has_pdf = True
                    else:
                        has_doc = True
                    if has_doc and has_pdf:
                        return "ã€å°è¯´+æ¼«ç”»ã€‘"
            if has_doc:
                return "ã€å°è¯´ã€‘"
            if has_pdf:
                return "ã€æ¼«ç”»ã€‘"
            return ""

        author_renames = []
        try:
            for name in sorted(os.listdir(lib_root)):
                p = os.path.join(lib_root, name)
                if not os.path.isdir(p):
                    continue
                try:
                    if os.path.islink(p):
                        continue
                except Exception:
                    pass
                base = strip_tag_prefix(name).strip()
                if not base:
                    continue
                tag = classify_author_dir(p)
                new_name = f"{tag}{base}"
                if new_name == str(name):
                    continue
                author_renames.append((str(name), new_name))
        except Exception:
            author_renames = []

        if author_renames and (not silent):
            print(Colors.cyan(f"å°†ä¸º {len(author_renames)} ä¸ªä½œè€…æ–‡ä»¶å¤¹æ·»åŠ åˆ†ç±»å‰ç¼€å–µ:"))
            show_n = 30
            for old_name, new_name in author_renames[:show_n]:
                print(Colors.cyan(f"  - {old_name} -> {new_name}"))
            if len(author_renames) > show_n:
                print(Colors.cyan(f"... è¿˜æœ‰ {len(author_renames) - show_n} ä¸ªæœªå±•ç¤ºå–µ"))

        extra = []
        if hash_updates:
            extra.append(f"è¡¥é½ hash {len(hash_updates)} æ¡")
        if relinks:
            extra.append(f"çº æ­£è·¯å¾„ {len(relinks)} æ¡")
        if adds:
            extra.append(f"è¡¥å½• {len(adds)} æ¡")
        if author_renames:
            extra.append(f"æ ‡è®°ä½œè€… {len(author_renames)} ä¸ª")

        if dry_run:
            if not silent:
                print(Colors.green("åŒæ­¥é¢„è§ˆå®Œæˆå–µï¼" + ("ï¼ˆ" + "ï¼Œ".join(extra) + "ï¼‰" if extra else "")))
            return

        if (not hash_updates) and (not relinks) and (not adds) and (not illegal_files):
            if not silent:
                print(Colors.green("åŒæ­¥å®Œæˆå–µï¼æ²¡æœ‰éœ€è¦æ›´æ–°çš„å†…å®¹~"))
            return

        if (not yes) and (not silent):
            ans = input(Colors.pink("é¢„è§ˆå¦‚ä¸Šï¼Œç»§ç»­æ‰§è¡ŒåŒæ­¥å—å–µï¼Ÿ(yes/no): ")).strip().lower()
            if ans not in {"y", "yes"}:
                print(Colors.cyan("æ“ä½œå–æ¶ˆäº†å–µ~"))
                return

        hash_filled = 0
        for bid, fh in hash_updates:
            try:
                if self.db.update_book(int(bid), file_hash=fh):
                    hash_filled += 1
            except Exception:
                pass

        relinked = 0
        for kid, fp_norm, file_type, fh in relinks:
            try:
                if self.db.update_book(int(kid), file_path=fp_norm, file_type=file_type, file_hash=fh):
                    relinked += 1
            except Exception:
                pass

        added = 0
        added_rows = []
        for title, author, tags, status, series, fp_norm, file_type, fh in adds:
            try:
                new_id = self.db.add_book(title, author, tags, status, series, fp_norm, file_type, file_hash=fh)
                added += 1
                added_rows.append((new_id, title, author, status, series, file_type))
            except Exception:
                pass

        if added_rows and (not silent):
            print(Colors.green(f"è¡¥å½•å®Œæˆå–µï¼å…±è¡¥å½• {len(added_rows)} æœ¬:"))
            show_n = 30
            for new_id, title, author, status, series, file_type in added_rows[:show_n]:
                st_s = Colors.green("å®Œç»“") if int(status or 0) == 1 else Colors.pink("è¿è½½")
                series_s = f"  {Colors.cyan('[' + str(series) + ']')}" if str(series or "").strip() else ""
                print(
                    f"  + {Colors.YELLOW}{str(file_type)}{Colors.RESET} "
                    f"[{Colors.yellow(str(new_id))}] {Colors.BOLD}{title}{Colors.RESET} - {Colors.green(author)} ({st_s}){series_s}"
                )
            if len(added_rows) > show_n:
                print(Colors.cyan(f"... è¿˜æœ‰ {len(added_rows) - show_n} æœ¬æœªå±•ç¤ºå–µ"))

        illegal_deleted = 0
        illegal_kept = 0
        if illegal_files and (not silent):
            if illegal_mode == "keep":
                illegal_kept = len(illegal_files)
            else:
                choice = None
                for x in illegal_files:
                    do_del = False
                    if illegal_mode == "always":
                        do_del = True
                    else:
                        if choice == "all":
                            do_del = True
                        elif choice == "none":
                            do_del = False
                        else:
                            ans = input(Colors.pink(f"åˆ é™¤éæ³•æ–‡ä»¶å—å–µï¼Ÿ(yes/no/all/none): {x} ")).strip().lower()
                            if ans in {"y", "yes"}:
                                do_del = True
                            elif ans in {"a", "all"}:
                                do_del = True
                                choice = "all"
                            elif ans in {"n", "no"}:
                                do_del = False
                            elif ans in {"none"}:
                                do_del = False
                                choice = "none"
                            else:
                                do_del = False

                    if do_del:
                        try:
                            lib_abs = abs_norm(lib_root)
                            x_abs = abs_norm(x)
                            if os.path.commonpath([x_abs, lib_abs]) != lib_abs:
                                print(Colors.red(f"ä¸ºå®‰å…¨èµ·è§ï¼Œè·³è¿‡åˆ é™¤(ä¸åœ¨è—ä¹¦ç›®å½•å†…)å–µ: {x}"))
                                illegal_kept += 1
                                continue
                        except Exception:
                            pass
                        try:
                            if self.fm.delete_file(x):
                                illegal_deleted += 1
                            else:
                                illegal_kept += 1
                        except Exception:
                            illegal_kept += 1
                    else:
                        illegal_kept += 1

        renamed = 0
        if author_renames:
            for old_name, new_name in author_renames:
                old_dir = os.path.normpath(os.path.join(lib_root, old_name))
                new_dir = os.path.normpath(os.path.join(lib_root, new_name))

                try:
                    lib_abs = abs_norm(lib_root)
                    old_abs = abs_norm(old_dir)
                    new_abs = abs_norm(new_dir)
                    if os.path.commonpath([old_abs, lib_abs]) != lib_abs:
                        continue
                    if os.path.commonpath([new_abs, lib_abs]) != lib_abs:
                        continue
                except Exception:
                    continue

                if not os.path.isdir(old_dir):
                    continue

                def merge_dir_content(src, dst):
                    import shutil
                    import time

                    if not os.path.exists(dst):
                        os.makedirs(dst)

                    for item in os.listdir(src):
                        s = os.path.join(src, item)
                        d = os.path.join(dst, item)

                        if os.path.isdir(s):
                            if os.path.exists(d) and os.path.isdir(d):
                                merge_dir_content(s, d)
                                try:
                                    os.rmdir(s)
                                except Exception:
                                    pass
                            elif os.path.exists(d):
                                ts = int(time.time() * 1000)
                                d_new = f"{d}_{ts}"
                                shutil.move(s, d_new)
                                try:
                                    s_prefix = s + os.sep
                                    d_prefix = d_new + os.sep
                                    self.db.conn.execute(
                                        "UPDATE books SET file_path = REPLACE(file_path, ?, ?) WHERE file_path LIKE ?",
                                        (s_prefix, d_prefix, s_prefix + "%"),
                                    )
                                except Exception:
                                    pass
                            else:
                                shutil.move(s, d)
                        else:
                            final_dst = d
                            if os.path.exists(d):
                                base, ext = os.path.splitext(item)
                                ts = int(time.time() * 1000)
                                final_dst = os.path.join(dst, f"{base}_{ts}{ext}")
                                shutil.move(s, final_dst)
                                try:
                                    self.db.conn.execute(
                                        "UPDATE books SET file_path = ? WHERE file_path = ?",
                                        (final_dst, s),
                                    )
                                except Exception:
                                    pass
                            else:
                                shutil.move(s, d)

                if os.path.exists(new_dir):
                    if not silent:
                        print(Colors.yellow(f"ç›®æ ‡ä½œè€…ç›®å½•å·²å­˜åœ¨ï¼Œæ­£åœ¨åˆå¹¶å–µ: {new_dir}"))

                    try:
                        merge_dir_content(old_dir, new_dir)
                        try:
                            shutil.rmtree(old_dir)
                        except Exception as e:
                            if not silent:
                                print(Colors.red(f"åˆ é™¤æ—§ç›®å½•å¤±è´¥å–µ: {e}"))
                        renamed += 1
                    except Exception as e:
                        if not silent:
                            print(Colors.red(f"åˆå¹¶ç›®å½•å¤±è´¥å–µ: {e}"))
                        continue
                else:
                    try:
                        os.rename(old_dir, new_dir)
                        renamed += 1
                    except Exception:
                        if not silent:
                            print(Colors.red(f"ä½œè€…ç›®å½•æ”¹åå¤±è´¥å–µ: {old_dir} -> {new_dir}"))
                        continue

                try:
                    prefix_old = os.path.normpath(os.path.join(lib_root, old_name)) + os.sep
                    prefix_new = os.path.normpath(os.path.join(lib_root, new_name)) + os.sep
                    cur = self.db.conn.cursor()
                    cur.execute(
                        "UPDATE books SET file_path = REPLACE(file_path, ?, ?) WHERE file_path LIKE ?",
                        (prefix_old, prefix_new, prefix_old + "%"),
                    )
                    self.db.conn.commit()
                except Exception:
                    pass

        if not silent:
            extra2 = []
            if hash_filled:
                extra2.append(f"è¡¥é½ hash {hash_filled} æ¡")
            if relinked:
                extra2.append(f"çº æ­£è·¯å¾„ {relinked} æ¡")
            if added:
                extra2.append(f"è¡¥å½• {added} æ¡")
            if illegal_deleted:
                extra2.append(f"åˆ é™¤éæ³• {illegal_deleted} ä¸ª")
            if illegal_kept and (illegal_mode == "keep"):
                extra2.append(f"ä¿ç•™éæ³• {illegal_kept} ä¸ª")
            if renamed:
                extra2.append(f"æ ‡è®°ä½œè€… {renamed} ä¸ª")
            print(Colors.green("åŒæ­¥å®Œæˆå–µï¼" + ("ï¼ˆ" + "ï¼Œ".join(extra2) + "ï¼‰" if extra2 else "")))

    def do_optimize(self, arg):
        """ä¼˜åŒ–æ•°æ®åº“: optimize [--yes]

        åŠŸèƒ½:
        1) é‡æ–°æ’åˆ—ä¹¦ç± IDï¼Œå¡«è¡¥ç©ºç¼ºï¼Œä½¿å…¶è¿ç»­ (1, 2, 3...)
        2) é‡ç½®è‡ªå¢åºåˆ—
        3) å‹ç¼©æ•°æ®åº“æ–‡ä»¶ (VACUUM)

        æ³¨æ„:
        - ä»…å½“æ‚¨ä¸ä¾èµ–ç‰¹å®š ID å¼•ç”¨ä¹¦ç±æ—¶ä½¿ç”¨
        - æ­¤æ“ä½œä¸å¯é€†ï¼Œå»ºè®®å…ˆå¤‡ä»½æ•°æ®åº“

        é€‰é¡¹:
        - --yes / -y: è·³è¿‡ç¡®è®¤
        """
        args = shlex.split(arg or "")
        yes = ("--yes" in args) or ("-y" in args)

        if not yes:
            print(Colors.red("âš ï¸  è­¦å‘Š: æ­¤æ“ä½œå°†é‡æ–°ç¼–å·æ‰€æœ‰ä¹¦ç± IDï¼"))
            print(Colors.yellow("åŸæ¥çš„ ID å°†ä¼šæ”¹å˜ï¼Œè¯·ç¡®ä¿æ²¡æœ‰å¤–éƒ¨å¼•ç”¨ä¾èµ–ç‰¹å®š IDã€‚"))
            confirm = input(Colors.cyan("ç¡®è®¤è¦ç»§ç»­å—å–µï¼Ÿ(y/N): ")).strip().lower()
            if confirm != "y":
                print(Colors.green("æ“ä½œå·²å–æ¶ˆå–µã€‚"))
                return

        print(Colors.cyan("æ­£åœ¨æ•´ç†ä¹¦æ¶ï¼Œè¯·ç¨å€™å–µ..."))

        try:
            all_books = sorted(self.db.list_books(), key=lambda x: x['id'])

            if not all_books:
                print(Colors.yellow("ä¹¦æ¶æ˜¯ç©ºçš„ï¼Œæ— éœ€ä¼˜åŒ–å–µã€‚"))
                return

            count = len(all_books)
            print(Colors.green(f"æ‰¾åˆ° {count} æœ¬ä¹¦ï¼Œå‡†å¤‡é‡æ’ ID..."))

            cursor = self.db.conn.cursor()
            cursor.execute("BEGIN TRANSACTION")

            try:
                books_data = []
                for b in all_books:
                    books_data.append(
                        {
                            'title': b['title'],
                            'author': b['author'],
                            'tags': b['tags'],
                            'status': b['status'],
                            'series': b['series'],
                            'file_path': b['file_path'],
                            'file_hash': b['file_hash'],
                            'file_type': b['file_type'],
                            'created_at': b['created_at'],
                        }
                    )

                cursor.execute("DELETE FROM books")
                cursor.execute("DELETE FROM sqlite_sequence WHERE name='books'")

                insert_sql = '''
                    INSERT INTO books (title, author, tags, status, series, file_path, file_hash, file_type, created_at)
                    VALUES (:title, :author, :tags, :status, :series, :file_path, :file_hash, :file_type, :created_at)
                '''
                cursor.executemany(insert_sql, books_data)

                self.db.conn.commit()
                print(Colors.green("ID é‡æ’å®Œæˆå–µï¼"))

                print(Colors.cyan("æ­£åœ¨å‹ç¼©æ•°æ®åº“ä½“ç§¯..."))
                self.db.conn.execute("VACUUM")
                print(Colors.green("ä¼˜åŒ–å…¨éƒ¨å®Œæˆï¼ä¹¦æ¶å˜å¾—æ•´æ•´é½é½å•¦å–µ~ âœ¨"))

            except Exception as e:
                self.db.conn.rollback()
                print(Colors.red(f"ä¼˜åŒ–å¤±è´¥ï¼Œå·²å›æ»šæ›´æ”¹: {e}"))
                import traceback

                traceback.print_exc()

        except Exception as e:
            print(Colors.red(f"å‘ç”Ÿé”™è¯¯: {e}"))

    def complete_clean(self, text, line, begidx, endidx):
        opts = [
            "--dry-run",
            "--fix",
            "--apply",
            "--yes",
            "--dir=",
            "--type=",
            "--ext=",
            "--since=",
            "--until=",
            "--resume-from=",
        ]
        return simple_complete(text, opts)

    def complete_optimize(self, text, line, begidx, endidx):
        opts = ["--yes"]
        return simple_complete(text, opts)

    def complete_help(self, text, line, begidx, endidx):
        cmds = [c[3:] for c in self.get_names() if c.startswith("do_")]
        return simple_complete(text, cmds)

    def preloop(self):
        self.do_clean(silent=True)

    def postloop(self):
        print(Colors.pink("\nèŒèŒå»ä¼‘æ¯äº†å–µ~ æ‹œæ‹œï¼"))
        self.db.close()

    def do_exit(self, arg):
        """é€€å‡ºç³»ç»Ÿ: exit"""
        return True


__all__ = ["SystemCommandsMixin"]
